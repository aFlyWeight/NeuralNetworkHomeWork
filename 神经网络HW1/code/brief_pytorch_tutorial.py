# -*- coding: utf-8 -*-
"""brief_pytorch_tutorial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GYXXHFZSltx7ffYGVuTv3VMqLfTbxCl8

## 安装pytorch
和在linux系统中安装类似，使用 ```pip```命令可以安装pytorch
"""

#!pip install torch torchvision

"""## pytorch基础

- tensor的创建方式
- tensor的数学运算
- tensor与numpy的相互转换
- tensor与GPU
"""

import torch 

a = torch.tensor(5)
print(a, a.dtype)

b = torch.tensor(1.5)
print(b, b.dtype)

c = torch.tensor([1,2,3,4])
print(c, c.dtype)

a_new = a.to(torch.float32)
print(a_new, a_new.dtype)

print(a)
# 数据默认在CPU上建立，如果GPU可用，将数据移动到GPU上
device = 'cuda' if torch.cuda.is_available() else 'cpu'

print(device)

#a_gpu = a.to(device) 
#print(a_gpu)

# pytorch 数据与 numpy 数据的转换

import numpy as np
np_array = np.random.randn(10,2)
print(np_array)
print('\n')

# numpy --> pytorch
py_array = torch.from_numpy(np_array)
print(py_array)
print('\n')

# pytorch --> numpy
new_np_array = py_array.numpy()
print(new_np_array)

# 查看GPU信息

#!nvidia-smi

"""## 简单的求导练习"""

import torch
# 简单的求导练习
# 3a + 4b = y
# dy/da = 3; dy/db =4

# 令 a = 2.3, b= 3.2
va = torch.tensor(2.3, requires_grad=True)
vb = torch.tensor(3.2, requires_grad=True)

y = 3 * va + 4 * vb
print('y = ', y)

# gradient calculation
y.backward()

print('dy/da = ', va.grad)
print('dy/db = ', vb.grad)

"""## 简单的例子"""

import matplotlib.pyplot as plt
import numpy as np
# 生成样本： label=0
x_pos = np.random.uniform(low=0, high=10, size=1000)
noise = np.random.uniform(low=1, high=2, size=1000)
y_pos = -1 * x_pos + 10 - noise 
label_pos = np.zeros(1000)

# 生成样本：label = 1
x_neg = np.random.uniform(low=0, high=10, size=1000)
noise = np.random.uniform(low=1, high=2, size=1000)
y_neg = -1 * x_neg + 10 + noise 
label_neg = np.ones(1000)

# 画出分割面 x+y-10 = 0
x_line = [0, 10]
y_line = [10, 0]
# 样本可视化
plt.scatter(x_pos, y_pos, color='r')
plt.scatter(x_neg, y_neg, color='b')
plt.plot(x_line, y_line, color='g')
plt.show()

# 组成矩阵

x_train = np.hstack([x_pos, x_neg])
y_train = np.hstack([y_pos, y_neg])
train_set = np.vstack([x_train, y_train])
train_set = train_set.T 

train_label = np.hstack([label_pos, label_neg])

print('train_set.shape = ', train_set.shape)
print(train_set)
print('\n')
print('train_label.shape = ', train_label.shape)
print(train_label)

# 将数据转换成 tensor
import torch

torch.cuda._initialized = True
device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
print(device)

train_data_pytorch = torch.from_numpy(train_set).float().to(device)
train_label_pytorch = torch.from_numpy(train_label).to(torch.long).to(device)
 
print(train_data_pytorch)
print(train_label_pytorch)

# 构建神经网络模型
import torch.nn as nn 
from torch.nn import functional as F

class SimpleNet(nn.Module):
  def __init__(self, D_in, Hidden, D_out):
    super(SimpleNet, self).__init__()
    self.linear_1 = nn.Linear(D_in, Hidden)
    self.linear_2 = nn.Linear(Hidden, D_out)
  
  def forward(self, x):
    x = F.sigmoid(self.linear_1(x))
    x = self.linear_2(x)
    return x

## 训练模型

import torch.optim as optim 

model = SimpleNet(2, 2, 2).to(device)

def main():
  criterion = nn.CrossEntropyLoss()
  lr = 0.1 # learning rate
  optimizer = optim.SGD(model.parameters(), lr=lr)
  epoch_num = 2500

  for ep in range(epoch_num):
    # train
    model.train()
    output = model(train_data_pytorch)
    loss = criterion(output, train_label_pytorch)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    # 每100次迭代输出训练集上的分类结果
    if (ep+1)%100 == 0:
      model.eval()
      p_out = model(train_data_pytorch)
      predict_labels = torch.argmax(p_out, 1).cpu().numpy()
      acc = np.sum(predict_labels == train_label) / 2000
      print('epoch num : {} -- Loss : {} -- Acc : {}'.format(ep+1,loss.data, acc))


main()

# 生成一些新的测试点进行测试
test_points = torch.tensor([[1,1],[4,7],[11,3],[-1,9],[0,7],[20,0]]).float().cuda() # 0, 1, 1, 0, 0, 1
model.eval()
test_output = model(test_points)
print(test_output)
print('\n')
print(torch.argmax(test_output, 1))
print('\n')

